{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0272b8",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction and Feature Selection  \n",
    "  \n",
    "The first thing done below is running a model with a feature set that includes 9 different feature types and 401 overall features. The goal is going to be to reduce that number and improve performance. One possibility is signal averaging. This can be done by region or using specific electrode chains defined by the EEG montage used for generating the spectrograms which were provided with this data. Another possibility is using PCA to reduce 401 columns down substantially while retaining a dataset that explains the strong majority of the variance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77bde38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import fastparquet, pyarrow\n",
    "import mne\n",
    "from mne.decoding import Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93df0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91998143",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('by_patient.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403a3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_metadata = activity_df(metadata, 'Other', 'expert_consensus')\n",
    "seizure_metadata = activity_df(metadata, 'Seizure', 'expert_consensus')\n",
    "gpd_metadata = activity_df(metadata, 'GPD', 'expert_consensus')\n",
    "lpd_metadata = activity_df(metadata, 'LPD', 'expert_consensus')\n",
    "grda_metadata = activity_df(metadata, 'GRDA', 'expert_consensus')\n",
    "lrda_metadata = activity_df(metadata, 'LRDA', 'expert_consensus')\n",
    "activity_df_list = [other_metadata, seizure_metadata, gpd_metadata, lpd_metadata, grda_metadata, lrda_metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d09122",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = get_yvals(2000)['activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8c1c6",
   "metadata": {},
   "source": [
    "### Features Included  \n",
    "  \n",
    "- Frequency Band Power  \n",
    "- Hjorth Complexity Time and Frequency  \n",
    "- Hjorth Mobility Time and Frequency  \n",
    "- Wavelet Coef Energy  \n",
    "- Higuchi  \n",
    "- Zero Crossings  \n",
    "- Spectral Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c0f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_features(stored_data):\n",
    "    X = pd.read_csv(stored_data)\n",
    "    cols = X.columns\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    return pd.DataFrame(X, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c092ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = ['band_pow_df.csv', 'time_comp_df.csv', 'freq_comp_df.csv',\n",
    "           'time_mob_df.csv', 'spectral_mob_df.csv', 'coef_energy_df.csv', 'higuchi_fd_set.csv', \n",
    "           'zero_xing_df.csv', 'spectslope_df.csv']\n",
    "X = pd.DataFrame()\n",
    "for df in df_list:\n",
    "    X = pd.concat([X, get_scaled_features(df)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ba9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b6b74",
   "metadata": {},
   "source": [
    "### Full Feature Set Results  \n",
    "  \n",
    "These results are the baseline for dimensionality reduction and feature selection work. The testing accuracy with the full feature set with all of the feature types listed above included is 76%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527e007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Set Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.86      0.94      0.90      1794\n",
      "        GRDA       0.84      0.89      0.87      1819\n",
      "         LPD       0.80      0.90      0.85      1800\n",
      "        LRDA       0.88      0.91      0.89      1795\n",
      "       Other       0.84      0.74      0.78      1808\n",
      "     Seizure       0.90      0.72      0.80      1784\n",
      "\n",
      "    accuracy                           0.85     10800\n",
      "   macro avg       0.85      0.85      0.85     10800\n",
      "weighted avg       0.85      0.85      0.85     10800\n",
      "\n",
      "Full Set Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.79      0.89      0.84       206\n",
      "        GRDA       0.72      0.79      0.75       181\n",
      "         LPD       0.69      0.83      0.76       200\n",
      "        LRDA       0.81      0.85      0.83       205\n",
      "       Other       0.72      0.60      0.65       192\n",
      "     Seizure       0.85      0.62      0.71       216\n",
      "\n",
      "    accuracy                           0.76      1200\n",
      "   macro avg       0.76      0.76      0.76      1200\n",
      "weighted avg       0.77      0.76      0.76      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Full Set Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Full Set Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "full_set_acc = accuracy_score(y_test, testing_yhat)\n",
    "full_set_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "full_set_macro_prec = precision_score(y_test, testing_yhat, average = 'macro')\n",
    "full_set_macro_rec = recall_score(y_test, testing_yhat, average = 'macro')\n",
    "full_set_f1 = f1_score(y_test, testing_yhat, average = None)\n",
    "full_set_prec = precision_score(y_test, testing_yhat, average = None)\n",
    "full_set_rec = recall_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a1685",
   "metadata": {},
   "source": [
    "### Signal Averaging: Bipolar Montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "addfedc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_eeg = load_preprocess(metadata, 0, names, montage_chains, 1, None,\n",
    "                      bandpass = True, notch = False, reref = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52b80931",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = mne.create_info(\n",
    "    sub_eeg.columns.to_list(),\n",
    "    ch_types=([\"eeg\"]*(len(sub_eeg.columns))),\n",
    "    sfreq=200\n",
    ")\n",
    "raw = mne.io.RawArray(\n",
    "    sub_eeg.to_numpy().T,\n",
    "    info\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa88b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_signals(raw, names, montage_chains):\n",
    "    sub_eeg = pd.DataFrame(raw.get_data(), index = raw.ch_names).transpose()\n",
    "    averages = []\n",
    "    for chain in montage_chains:\n",
    "        signal_sum = 0\n",
    "        for i in chain:\n",
    "            signal_sum += sub_eeg[i]\n",
    "        avg_signal = signal_sum / 4\n",
    "        averages.append(avg_signal)\n",
    "    avg_eeg = pd.DataFrame(averages, index = names).transpose()\n",
    "    info = mne.create_info(\n",
    "        avg_eeg.columns.to_list(),\n",
    "        ch_types=([\"eeg\"]*(len(avg_eeg.columns))),\n",
    "        sfreq=200\n",
    "    )\n",
    "    raw = mne.io.RawArray(\n",
    "        avg_eeg.to_numpy().T,\n",
    "        info\n",
    "    )\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41f70825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55107978",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_indexes = pd.read_csv('activity_indexes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5409d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_lists = [activity_indexes[col] for col in activity_indexes.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5cd52e",
   "metadata": {},
   "source": [
    "### Attempt with Band Power Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd29093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ['LL','LP','RP','RR', 'Central']\n",
    "\n",
    "mc = [['Fp1','F7','T3','T5','O1'],\n",
    "      ['Fp1','F3','C3','P3','O1'],\n",
    "      ['Fp2','F8','T4','T6','O2'],\n",
    "      ['Fp2','F4','C4','P4','O2'], \n",
    "      ['Fz', 'Cz', 'Pz']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0356853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "montage_bandpower = full_band_df(activity_df_list, index_lists, n, mc, 1, None, \n",
    "                                bandpass = True, notch = False, reref = True)\n",
    "montage_bandpower.to_csv('montage_bandpower.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0efa8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('montage_bandpower.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05259152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montage Averaging Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.75      0.92      0.82      1794\n",
      "        GRDA       0.73      0.83      0.78      1819\n",
      "         LPD       0.73      0.84      0.78      1800\n",
      "        LRDA       0.78      0.86      0.81      1795\n",
      "       Other       0.75      0.53      0.62      1808\n",
      "     Seizure       0.84      0.58      0.69      1784\n",
      "\n",
      "    accuracy                           0.76     10800\n",
      "   macro avg       0.76      0.76      0.75     10800\n",
      "weighted avg       0.76      0.76      0.75     10800\n",
      "\n",
      "Montage Averaging Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.70      0.83      0.76       206\n",
      "        GRDA       0.58      0.65      0.61       181\n",
      "         LPD       0.62      0.72      0.66       200\n",
      "        LRDA       0.67      0.77      0.72       205\n",
      "       Other       0.51      0.35      0.42       192\n",
      "     Seizure       0.73      0.50      0.59       216\n",
      "\n",
      "    accuracy                           0.64      1200\n",
      "   macro avg       0.63      0.64      0.63      1200\n",
      "weighted avg       0.64      0.64      0.63      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Montage Averaging Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Montage Averaging Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "montage_acc = accuracy_score(y_test, testing_yhat)\n",
    "montage_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "montage_macro_prec = precision_score(y_test, testing_yhat, average = 'macro')\n",
    "montage_macro_rec = recall_score(y_test, testing_yhat, average = 'macro')\n",
    "montage_f1 = f1_score(y_test, testing_yhat, average = None)\n",
    "montage_prec = precision_score(y_test, testing_yhat, average = None)\n",
    "montage_rec = recall_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e15148",
   "metadata": {},
   "source": [
    "### Hjorth  \n",
    "  \n",
    "Before running the code below, I need to check the utils functions to be sure that everything has been correctly adjusted for the new EEGs which have 5 columns after signal averaging instead of 20 columns with 19 of them being EEG and the 20th being EKG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "montage_tcomp = full_complexity_df(activity_df_list, index_lists, n, mc, 1, None, \n",
    "                                bandpass = True, notch = False, reref = True, spectral = False)\n",
    "montage_tcomp.to_csv('montage_tcomp.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
