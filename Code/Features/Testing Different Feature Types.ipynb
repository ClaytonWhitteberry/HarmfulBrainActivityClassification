{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0272b8",
   "metadata": {},
   "source": [
    "### Testing Different Feature Types  \n",
    "  \n",
    "For each of these feature sets, the EEG preprocessing will involve standardization, highpass filtering, and re-referencing with the global average of the 19 scalp electrodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f77bde38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import fastparquet, pyarrow\n",
    "import mne\n",
    "from scipy.stats import kurtosis, skew\n",
    "from mne.decoding import Scaler\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93df0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91998143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('by_patient.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8933b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_df = activity_df(df, 'Other', 'expert_consensus')\n",
    "seizure_df = activity_df(df, 'Seizure', 'expert_consensus')\n",
    "gpd_df = activity_df(df, 'GPD', 'expert_consensus')\n",
    "lpd_df = activity_df(df, 'LPD', 'expert_consensus')\n",
    "grda_df = activity_df(df, 'GRDA', 'expert_consensus')\n",
    "lrda_df = activity_df(df, 'LRDA', 'expert_consensus')\n",
    "activity_df_list = [other_df, seizure_df, gpd_df, lpd_df, grda_df, lrda_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954a9b7a",
   "metadata": {},
   "source": [
    "### Frequency Band Power  \n",
    "  \n",
    "EEG time series data is transformed into the frequency domain using Welch's method. The power of the signal within specified frequency bands is determined and used as feature data. There are five frequency bands: delta (0.5 - 4), theta (4 - 8), alpha (8 - 13), beta (13 - 30), gamma (30 - 100). Five band powers per EEG channel means 95 columns in the feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0b9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = get_yvals(2000)['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbdfda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('glb_avg_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4a9ed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band Power Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.83      0.93      0.88      1794\n",
      "        GRDA       0.78      0.89      0.83      1819\n",
      "         LPD       0.79      0.88      0.83      1800\n",
      "        LRDA       0.85      0.89      0.87      1795\n",
      "       Other       0.78      0.63      0.70      1808\n",
      "     Seizure       0.90      0.69      0.78      1784\n",
      "\n",
      "    accuracy                           0.82     10800\n",
      "   macro avg       0.82      0.82      0.81     10800\n",
      "weighted avg       0.82      0.82      0.81     10800\n",
      "\n",
      "Band Power Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.73      0.87      0.80       206\n",
      "        GRDA       0.66      0.81      0.72       181\n",
      "         LPD       0.70      0.78      0.74       200\n",
      "        LRDA       0.80      0.79      0.80       205\n",
      "       Other       0.51      0.45      0.48       192\n",
      "     Seizure       0.81      0.53      0.64       216\n",
      "\n",
      "    accuracy                           0.70      1200\n",
      "   macro avg       0.70      0.70      0.70      1200\n",
      "weighted avg       0.71      0.70      0.70      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Band Power Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Band Power Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "band_power_acc = accuracy_score(y_test, testing_yhat)\n",
    "band_power_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "band_power_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1eca839",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandpow_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "bandpow_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875dc04d",
   "metadata": {},
   "source": [
    "### Frequency Band Energy  \n",
    "  \n",
    "Only difference is this is calculating energy for each EEG channel after transformation into the frequency domain instead of power as was done above.  \n",
    "  \n",
    "**ERROR:**  \n",
    "  \n",
    "Running the code to get the band energy feature data returned an error saying that the lowpass filter needed to be less than the nyquist frequency (sampling frequency / 2; determines the maximum frequency for the frequency domain of the data) which is 100 Hz for this data. I adjusted the lowpass filter, but it didn't resolve the issue, so I think there's a parameter setting for the compute_energy_freq_bands function that needs to be adjusted, but I don't know exactly how to do that. Moving on to other feature types. First are the fractal dimension features: Katz and Higuchi.  \n",
    "  \n",
    "### Katz Fractal Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfdd2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#katz_features = full_katz_df(2000, activity_df_list, 1, None, bandpass = True, notch = False, reref = True)\n",
    "#katz_features.to_csv('katz_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72071a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('katz_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd01e009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katz Fractal Dimension Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.79      0.89      0.84      1794\n",
      "        GRDA       0.74      0.83      0.78      1819\n",
      "         LPD       0.72      0.82      0.77      1800\n",
      "        LRDA       0.80      0.85      0.82      1795\n",
      "       Other       0.75      0.53      0.62      1808\n",
      "     Seizure       0.76      0.66      0.71      1784\n",
      "\n",
      "    accuracy                           0.76     10800\n",
      "   macro avg       0.76      0.76      0.76     10800\n",
      "weighted avg       0.76      0.76      0.76     10800\n",
      "\n",
      "Katz Fractal Dimension Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.72      0.84      0.78       206\n",
      "        GRDA       0.57      0.66      0.61       181\n",
      "         LPD       0.62      0.70      0.66       200\n",
      "        LRDA       0.67      0.75      0.71       205\n",
      "       Other       0.52      0.33      0.40       192\n",
      "     Seizure       0.66      0.52      0.58       216\n",
      "\n",
      "    accuracy                           0.64      1200\n",
      "   macro avg       0.63      0.63      0.62      1200\n",
      "weighted avg       0.63      0.64      0.62      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Katz Fractal Dimension Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Katz Fractal Dimension Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "katz_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "katz_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "katz_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "katz_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56644994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.761, 0.635)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "katz_train, katz_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5785e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = pd.DataFrame(band_power_f1, index = ['GPD', 'GRDA', 'LPD', 'LRDA', 'Other', 'Seizure'], columns = ['Band Power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e472df",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Katz'] = katz_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99475fca",
   "metadata": {},
   "source": [
    "### Higuchi Fractal Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30aefb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#higuchi_df = full_higuchi_df(2000, activity_df_list, 1, None, bandpass = True, notch = False, reref = True)\n",
    "#higuchi_df.to_csv('higuchi_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5bd7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('higuchi_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6511fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higuchi Fractal Dimension Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.84      0.90      0.87      1794\n",
      "        GRDA       0.80      0.83      0.82      1819\n",
      "         LPD       0.74      0.87      0.80      1800\n",
      "        LRDA       0.85      0.89      0.87      1795\n",
      "       Other       0.76      0.58      0.66      1808\n",
      "     Seizure       0.79      0.72      0.75      1784\n",
      "\n",
      "    accuracy                           0.80     10800\n",
      "   macro avg       0.80      0.80      0.79     10800\n",
      "weighted avg       0.80      0.80      0.79     10800\n",
      "\n",
      "Higuchi Fractal Dimension Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.84      0.77      0.80       206\n",
      "        GRDA       0.68      0.71      0.69       181\n",
      "         LPD       0.62      0.72      0.67       200\n",
      "        LRDA       0.76      0.82      0.79       205\n",
      "       Other       0.58      0.46      0.51       192\n",
      "     Seizure       0.58      0.57      0.58       216\n",
      "\n",
      "    accuracy                           0.68      1200\n",
      "   macro avg       0.68      0.68      0.67      1200\n",
      "weighted avg       0.68      0.68      0.67      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Higuchi Fractal Dimension Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Higuchi Fractal Dimension Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "higuchi_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "higuchi_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "higuchi_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "higuchi_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a06264b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.798, 0.677)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higuchi_train, higuchi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b87bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Higuchi'] = higuchi_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ec76674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band Power</th>\n",
       "      <th>Katz</th>\n",
       "      <th>Higuchi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPD</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRDA</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPD</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LRDA</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.482</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seizure</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Band Power   Katz  Higuchi\n",
       "GPD           0.796  0.777    0.803\n",
       "GRDA          0.725  0.611    0.694\n",
       "LPD           0.738  0.659    0.665\n",
       "LRDA          0.796  0.705    0.789\n",
       "Other         0.482  0.401    0.513\n",
       "Seizure       0.640  0.580    0.577"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores.round(decimals = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa79182",
   "metadata": {},
   "source": [
    "### Zero Crossings  \n",
    "  \n",
    "This is a measure of how often the signal crosses zero. In other words, how often the signal moves from + to - and from - to +."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2ec84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero_xing_df = full_zero_xing_df(2000, activity_df_list, 1, None, bandpass = True, notch = False, reref = True)\n",
    "#zero_xing_df.to_csv('zero_xing_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80dab956",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('zero_xing_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcbc1bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Crossings Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.82      0.90      0.86      1794\n",
      "        GRDA       0.82      0.83      0.83      1819\n",
      "         LPD       0.77      0.84      0.80      1800\n",
      "        LRDA       0.85      0.88      0.86      1795\n",
      "       Other       0.77      0.60      0.68      1808\n",
      "     Seizure       0.77      0.75      0.76      1784\n",
      "\n",
      "    accuracy                           0.80     10800\n",
      "   macro avg       0.80      0.80      0.80     10800\n",
      "weighted avg       0.80      0.80      0.80     10800\n",
      "\n",
      "Zero Crossings Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.72      0.80      0.76       206\n",
      "        GRDA       0.68      0.65      0.66       181\n",
      "         LPD       0.61      0.73      0.67       200\n",
      "        LRDA       0.77      0.79      0.78       205\n",
      "       Other       0.53      0.46      0.49       192\n",
      "     Seizure       0.65      0.54      0.59       216\n",
      "\n",
      "    accuracy                           0.66      1200\n",
      "   macro avg       0.66      0.66      0.66      1200\n",
      "weighted avg       0.66      0.66      0.66      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Zero Crossings Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Zero Crossings Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "zero_xing_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "zero_xing_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "zero_xing_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "zero_xing_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68e968a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.801, 0.663)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_xing_train, zero_xing_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9246d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Zero Crossings'] = zero_xing_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7f5de86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band Power</th>\n",
       "      <th>Katz</th>\n",
       "      <th>Higuchi</th>\n",
       "      <th>Zero Crossings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPD</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRDA</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPD</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LRDA</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.482</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seizure</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Band Power   Katz  Higuchi  Zero Crossings\n",
       "GPD           0.796  0.777    0.803           0.755\n",
       "GRDA          0.725  0.611    0.694           0.694\n",
       "LPD           0.738  0.659    0.665           0.654\n",
       "LRDA          0.796  0.705    0.789           0.805\n",
       "Other         0.482  0.401    0.513           0.469\n",
       "Seizure       0.640  0.580    0.577           0.580"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores.round(decimals = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25cf21b",
   "metadata": {},
   "source": [
    "### Hjorth Complexity: Time-Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cad91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comp_df = full_complexity_df(2000, activity_df_list, 1, None, bandpass = True, notch = False, reref = True, spectral = False)\n",
    "#comp_df.to_csv('comp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a97bf151",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('comp_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c192663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hjorth Complexity Time Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.76      0.91      0.83      1794\n",
      "        GRDA       0.83      0.83      0.83      1819\n",
      "         LPD       0.74      0.85      0.79      1800\n",
      "        LRDA       0.84      0.87      0.85      1795\n",
      "       Other       0.77      0.57      0.65      1808\n",
      "     Seizure       0.77      0.70      0.73      1784\n",
      "\n",
      "    accuracy                           0.79     10800\n",
      "   macro avg       0.79      0.79      0.78     10800\n",
      "weighted avg       0.79      0.79      0.78     10800\n",
      "\n",
      "Hjorth Complexity Time Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.68      0.86      0.76       206\n",
      "        GRDA       0.70      0.75      0.72       181\n",
      "         LPD       0.65      0.76      0.70       200\n",
      "        LRDA       0.76      0.79      0.78       205\n",
      "       Other       0.58      0.30      0.39       192\n",
      "     Seizure       0.65      0.62      0.64       216\n",
      "\n",
      "    accuracy                           0.68      1200\n",
      "   macro avg       0.67      0.68      0.66      1200\n",
      "weighted avg       0.67      0.68      0.67      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Hjorth Complexity Time Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Hjorth Complexity Time Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "comp_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "comp_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "comp_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "comp_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "458b96d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.785, 0.68)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_train, comp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e7c1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Time-Domain Complexity'] = comp_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37f66c5",
   "metadata": {},
   "source": [
    "### Hjorth Complexity: Frequency-Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cc86b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comp_df = full_complexity_df(2000, activity_df_list, 1, None, bandpass = True, notch = False, reref = True, spectral = True)\n",
    "#comp_df.to_csv('comp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2849e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comp_df.to_csv('spectral_comp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5aa0f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('spectral_comp_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e4dbfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hjorth Complexity Frequency Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.72      0.89      0.80      1794\n",
      "        GRDA       0.73      0.80      0.77      1819\n",
      "         LPD       0.68      0.79      0.73      1800\n",
      "        LRDA       0.75      0.82      0.79      1795\n",
      "       Other       0.73      0.50      0.59      1808\n",
      "     Seizure       0.77      0.57      0.65      1784\n",
      "\n",
      "    accuracy                           0.73     10800\n",
      "   macro avg       0.73      0.73      0.72     10800\n",
      "weighted avg       0.73      0.73      0.72     10800\n",
      "\n",
      "Hjorth Complexity Frequency Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.65      0.83      0.73       206\n",
      "        GRDA       0.56      0.68      0.61       181\n",
      "         LPD       0.52      0.70      0.60       200\n",
      "        LRDA       0.67      0.72      0.69       205\n",
      "       Other       0.53      0.26      0.34       192\n",
      "     Seizure       0.68      0.42      0.52       216\n",
      "\n",
      "    accuracy                           0.60      1200\n",
      "   macro avg       0.60      0.60      0.58      1200\n",
      "weighted avg       0.60      0.60      0.58      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Hjorth Complexity Frequency Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Hjorth Complexity Frequency Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "spectral_comp_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "spectral_comp_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "spectral_comp_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "spectral_comp_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79e47558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.729, 0.602)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral_comp_train, spectral_comp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14e47a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Spectral Complexity'] = spectral_comp_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0c37a",
   "metadata": {},
   "source": [
    "### Hjorth Mobility: Time-Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54e572de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mob_df = full_mobility_df(2000, activity_df_list, 1, None, bandpass = True, notch = False, reref = True, spectral = False)\n",
    "#mob_df.to_csv('mob_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d53ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('mob_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11c639eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hjorth Mobility Time Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.78      0.90      0.83      1794\n",
      "        GRDA       0.80      0.83      0.82      1819\n",
      "         LPD       0.75      0.85      0.80      1800\n",
      "        LRDA       0.85      0.88      0.86      1795\n",
      "       Other       0.79      0.55      0.65      1808\n",
      "     Seizure       0.76      0.71      0.74      1784\n",
      "\n",
      "    accuracy                           0.79     10800\n",
      "   macro avg       0.79      0.79      0.78     10800\n",
      "weighted avg       0.79      0.79      0.78     10800\n",
      "\n",
      "Hjorth Mobility Time Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.68      0.79      0.73       206\n",
      "        GRDA       0.64      0.66      0.65       181\n",
      "         LPD       0.61      0.68      0.64       200\n",
      "        LRDA       0.70      0.79      0.74       205\n",
      "       Other       0.51      0.34      0.41       192\n",
      "     Seizure       0.61      0.54      0.57       216\n",
      "\n",
      "    accuracy                           0.64      1200\n",
      "   macro avg       0.62      0.63      0.62      1200\n",
      "weighted avg       0.63      0.64      0.63      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Hjorth Mobility Time Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Hjorth Mobility Time Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "mob_acc = accuracy_score(y_test, testing_yhat)\n",
    "mob_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "mob_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "704088a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Time-Domain Mobility'] = mob_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f22d378",
   "metadata": {},
   "source": [
    "### Hjorth Mobility: Frequency-Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "208e3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spectral_mob_df = full_mobility_df(2000, activity_df_list, 1, None, bandpass = True, notch = False, reref = True, spectral = True)\n",
    "#spectral_mob_df.to_csv('spectral_mob_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b1c284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('spectral_mob_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "172a9502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hjorth Mobility Frequency Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.74      0.88      0.81      1794\n",
      "        GRDA       0.72      0.80      0.76      1819\n",
      "         LPD       0.71      0.79      0.75      1800\n",
      "        LRDA       0.77      0.84      0.80      1795\n",
      "       Other       0.75      0.52      0.61      1808\n",
      "     Seizure       0.78      0.61      0.68      1784\n",
      "\n",
      "    accuracy                           0.74     10800\n",
      "   macro avg       0.74      0.74      0.74     10800\n",
      "weighted avg       0.74      0.74      0.74     10800\n",
      "\n",
      "Hjorth Mobility Frequency Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.64      0.78      0.70       206\n",
      "        GRDA       0.56      0.66      0.60       181\n",
      "         LPD       0.58      0.64      0.60       200\n",
      "        LRDA       0.67      0.75      0.71       205\n",
      "       Other       0.50      0.32      0.39       192\n",
      "     Seizure       0.58      0.44      0.50       216\n",
      "\n",
      "    accuracy                           0.60      1200\n",
      "   macro avg       0.59      0.60      0.58      1200\n",
      "weighted avg       0.59      0.60      0.58      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Hjorth Mobility Frequency Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Hjorth Mobility Frequency Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "spectral_mob_acc = accuracy_score(y_test, testing_yhat)\n",
    "spectral_mob_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "spectral_mob_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f6ffac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Spectral Mobility'] = spectral_mob_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f7831",
   "metadata": {},
   "source": [
    "### Line Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db3f5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linelength_df = full_linelength_df(2000, activity_df_list, 1, None, bandpass = True,\n",
    "                                  notch = False, reref = True)\n",
    "#linelength_df.to_csv('linelength_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aebf69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('linelength_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f880135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line Length Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.78      0.89      0.83      1794\n",
      "        GRDA       0.78      0.83      0.80      1819\n",
      "         LPD       0.72      0.83      0.77      1800\n",
      "        LRDA       0.80      0.86      0.83      1795\n",
      "       Other       0.79      0.54      0.64      1808\n",
      "     Seizure       0.76      0.67      0.71      1784\n",
      "\n",
      "    accuracy                           0.77     10800\n",
      "   macro avg       0.77      0.77      0.77     10800\n",
      "weighted avg       0.77      0.77      0.77     10800\n",
      "\n",
      "Line Length Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.72      0.76      0.74       206\n",
      "        GRDA       0.63      0.72      0.67       181\n",
      "         LPD       0.58      0.74      0.65       200\n",
      "        LRDA       0.72      0.76      0.74       205\n",
      "       Other       0.56      0.38      0.45       192\n",
      "     Seizure       0.67      0.55      0.60       216\n",
      "\n",
      "    accuracy                           0.65      1200\n",
      "   macro avg       0.65      0.65      0.64      1200\n",
      "weighted avg       0.65      0.65      0.64      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Line Length Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Line Length Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "linelength_acc = accuracy_score(y_test, testing_yhat)\n",
    "linelength_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "linelength_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d89440af",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Line Length'] = linelength_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0fdac",
   "metadata": {},
   "source": [
    "### Decorrelation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99d73de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decorr_time_df = full_decorr_df(2000, activity_df_list, 1, None, bandpass = True,\n",
    "                               notch = False, reref = True)\n",
    "#decorr_time_df.to_csv('decorr_time_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c759656",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('decorr_time_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630b603",
   "metadata": {},
   "source": [
    "### Worst Results by Wide Margin  \n",
    "  \n",
    "Follows the trend of the other feature sets with the four generalized and lateralized activities showing the best results of the 6 and then a large drop off to other and seizure. Performance is worse across the board relative to the other feature sets and the big difference that distinguishes this feature set from the others is that other and seizure show essentially equivalent results by precision, recall, and f1. The feature sets before this showed better results with seizure than other.  \n",
    "  \n",
    "I won't be using this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89630491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decorrelation Time Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.70      0.89      0.79      1794\n",
      "        GRDA       0.65      0.78      0.71      1819\n",
      "         LPD       0.69      0.72      0.70      1800\n",
      "        LRDA       0.74      0.80      0.77      1795\n",
      "       Other       0.67      0.50      0.58      1808\n",
      "     Seizure       0.74      0.48      0.58      1784\n",
      "\n",
      "    accuracy                           0.70     10800\n",
      "   macro avg       0.70      0.70      0.69     10800\n",
      "weighted avg       0.70      0.70      0.69     10800\n",
      "\n",
      "Decorrelation Time Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.57      0.76      0.65       206\n",
      "        GRDA       0.51      0.67      0.58       181\n",
      "         LPD       0.45      0.48      0.47       200\n",
      "        LRDA       0.65      0.68      0.67       205\n",
      "       Other       0.49      0.33      0.39       192\n",
      "     Seizure       0.52      0.31      0.39       216\n",
      "\n",
      "    accuracy                           0.54      1200\n",
      "   macro avg       0.53      0.54      0.52      1200\n",
      "weighted avg       0.53      0.54      0.52      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Decorrelation Time Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Decorrelation Time Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "decorr_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "decorr_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "decorr_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "decorr_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18d02a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.697, 0.538)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decorr_train, decorr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "574094fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Decorr Time'] = decorr_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b53204",
   "metadata": {},
   "source": [
    "### Spectral Edge Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b4f0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge_freq_df = full_edge_freq_df(2000, activity_df_list, 1, None, bandpass = True,\n",
    "                                notch = False, reref = True)\n",
    "#edge_freq_df.to_csv('edge_freq_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1443a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('edge_freq_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cce65c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Edge Frequency Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.71      0.88      0.78      1794\n",
      "        GRDA       0.66      0.73      0.69      1819\n",
      "         LPD       0.71      0.72      0.72      1800\n",
      "        LRDA       0.68      0.79      0.73      1795\n",
      "       Other       0.71      0.51      0.60      1808\n",
      "     Seizure       0.78      0.58      0.66      1784\n",
      "\n",
      "    accuracy                           0.70     10800\n",
      "   macro avg       0.71      0.70      0.70     10800\n",
      "weighted avg       0.71      0.70      0.70     10800\n",
      "\n",
      "Spectral Edge Frequency Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.64      0.80      0.71       206\n",
      "        GRDA       0.50      0.59      0.54       181\n",
      "         LPD       0.61      0.65      0.63       200\n",
      "        LRDA       0.59      0.69      0.64       205\n",
      "       Other       0.53      0.31      0.39       192\n",
      "     Seizure       0.66      0.50      0.57       216\n",
      "\n",
      "    accuracy                           0.59      1200\n",
      "   macro avg       0.59      0.59      0.58      1200\n",
      "weighted avg       0.59      0.59      0.58      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Spectral Edge Frequency Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Spectral Edge Frequency Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "edge_freq_acc = accuracy_score(y_test, testing_yhat)\n",
    "edge_freq_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "edge_freq_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "622eedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Edge Frequency'] = edge_freq_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd803666",
   "metadata": {},
   "source": [
    "### Spectral Slope  \n",
    "  \n",
    "Returns slope, intercept, mse, and r2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7238b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spect_slope_df = full_spect_slope_df(2000, activity_df_list, 1, None, bandpass = True,\n",
    "                                    notch = False, reref = True)\n",
    "#spect_slope_df.to_csv('spect_slope_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5aade3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('spect_slope_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3407ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Slope Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.85      0.92      0.89      1794\n",
      "        GRDA       0.75      0.88      0.81      1819\n",
      "         LPD       0.79      0.87      0.83      1800\n",
      "        LRDA       0.81      0.89      0.85      1795\n",
      "       Other       0.76      0.60      0.67      1808\n",
      "     Seizure       0.86      0.64      0.74      1784\n",
      "\n",
      "    accuracy                           0.80     10800\n",
      "   macro avg       0.80      0.80      0.80     10800\n",
      "weighted avg       0.80      0.80      0.80     10800\n",
      "\n",
      "Spectral Slope Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.75      0.84      0.79       206\n",
      "        GRDA       0.62      0.76      0.68       181\n",
      "         LPD       0.64      0.79      0.70       200\n",
      "        LRDA       0.74      0.78      0.76       205\n",
      "       Other       0.61      0.47      0.53       192\n",
      "     Seizure       0.79      0.49      0.60       216\n",
      "\n",
      "    accuracy                           0.69      1200\n",
      "   macro avg       0.69      0.69      0.68      1200\n",
      "weighted avg       0.69      0.69      0.68      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Spectral Slope Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Spectral Slope Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "spect_slope_acc = accuracy_score(y_test, testing_yhat)\n",
    "spect_slope_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "spect_slope_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0022f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Spectral Slope'] = spect_slope_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b17359",
   "metadata": {},
   "source": [
    "### Wavelet Coef Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77ff75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef_energy_df = full_coef_energy_df('db4', 2000, activity_df_list, 1, None, bandpass = True,\n",
    "                                    notch = False, reref = True)\n",
    "#coef_energy_df.to_csv('coef_energy_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31496bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('coef_energy_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "983d253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wavelet Coef Energy Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.82      0.93      0.87      1794\n",
      "        GRDA       0.77      0.87      0.82      1819\n",
      "         LPD       0.79      0.87      0.83      1800\n",
      "        LRDA       0.80      0.89      0.84      1795\n",
      "       Other       0.77      0.62      0.69      1808\n",
      "     Seizure       0.87      0.61      0.72      1784\n",
      "\n",
      "    accuracy                           0.80     10800\n",
      "   macro avg       0.80      0.80      0.79     10800\n",
      "weighted avg       0.80      0.80      0.79     10800\n",
      "\n",
      "Wavelet Coef Energy Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.73      0.86      0.79       206\n",
      "        GRDA       0.59      0.72      0.65       181\n",
      "         LPD       0.64      0.76      0.70       200\n",
      "        LRDA       0.72      0.80      0.75       205\n",
      "       Other       0.51      0.38      0.44       192\n",
      "     Seizure       0.77      0.46      0.58       216\n",
      "\n",
      "    accuracy                           0.66      1200\n",
      "   macro avg       0.66      0.66      0.65      1200\n",
      "weighted avg       0.66      0.66      0.65      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Wavelet Coef Energy Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Wavelet Coef Energy Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "coef_energy_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "coef_energy_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "coef_energy_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "coef_energy_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "914f8db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.799, 0.663)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_energy_train, coef_energy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b541ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Coef Energy'] = coef_energy_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4df546",
   "metadata": {},
   "source": [
    "### Teager Kaiser Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75a3c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tk_energy_df = full_tk_energy_df('db4', 2000, activity_df_list, 1, None, bandpass = True,\n",
    "                                notch = False, reref = True)\n",
    "#tk_energy_df.to_csv('tk_energy_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa34a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('tk_energy_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c42a316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teager Kaiser Energy Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.82      0.93      0.88      1794\n",
      "        GRDA       0.76      0.88      0.82      1819\n",
      "         LPD       0.78      0.85      0.81      1800\n",
      "        LRDA       0.80      0.90      0.85      1795\n",
      "       Other       0.78      0.61      0.68      1808\n",
      "     Seizure       0.88      0.63      0.74      1784\n",
      "\n",
      "    accuracy                           0.80     10800\n",
      "   macro avg       0.80      0.80      0.80     10800\n",
      "weighted avg       0.80      0.80      0.80     10800\n",
      "\n",
      "Teager Kaiser Energy Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.75      0.86      0.80       206\n",
      "        GRDA       0.63      0.74      0.68       181\n",
      "         LPD       0.68      0.75      0.71       200\n",
      "        LRDA       0.68      0.76      0.72       205\n",
      "       Other       0.56      0.47      0.51       192\n",
      "     Seizure       0.74      0.49      0.59       216\n",
      "\n",
      "    accuracy                           0.68      1200\n",
      "   macro avg       0.67      0.68      0.67      1200\n",
      "weighted avg       0.68      0.68      0.67      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Teager Kaiser Energy Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Teager Kaiser Energy Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "tk_energy_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "tk_energy_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "tk_energy_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "tk_energy_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45217a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.801, 0.678)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_energy_train, tk_energy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b058c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['Teager Kaiser'] = tk_energy_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "655abf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band Power</th>\n",
       "      <th>Katz</th>\n",
       "      <th>Higuchi</th>\n",
       "      <th>Zero Crossings</th>\n",
       "      <th>Time-Domain Complexity</th>\n",
       "      <th>Spectral Complexity</th>\n",
       "      <th>Time-Domain Mobility</th>\n",
       "      <th>Spectral Mobility</th>\n",
       "      <th>Line Length</th>\n",
       "      <th>Decorr Time</th>\n",
       "      <th>Edge Frequency</th>\n",
       "      <th>Spectral Slope</th>\n",
       "      <th>Coef Energy</th>\n",
       "      <th>Teager Kaiser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPD</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRDA</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPD</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LRDA</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.482</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seizure</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Band Power   Katz  Higuchi  Zero Crossings  Time-Domain Complexity  \\\n",
       "GPD           0.796  0.777    0.803           0.755                   0.761   \n",
       "GRDA          0.725  0.611    0.694           0.694                   0.724   \n",
       "LPD           0.738  0.659    0.665           0.654                   0.699   \n",
       "LRDA          0.796  0.705    0.789           0.805                   0.775   \n",
       "Other         0.482  0.401    0.513           0.469                   0.393   \n",
       "Seizure       0.640  0.580    0.577           0.580                   0.635   \n",
       "\n",
       "         Spectral Complexity  Time-Domain Mobility  Spectral Mobility  \\\n",
       "GPD                    0.726                 0.731              0.700   \n",
       "GRDA                   0.613                 0.649              0.603   \n",
       "LPD                    0.601                 0.643              0.605   \n",
       "LRDA                   0.692                 0.743              0.708   \n",
       "Other                  0.344                 0.408              0.391   \n",
       "Seizure                0.521                 0.572              0.496   \n",
       "\n",
       "         Line Length  Decorr Time  Edge Frequency  Spectral Slope  \\\n",
       "GPD            0.739        0.654           0.711           0.790   \n",
       "GRDA           0.670        0.579           0.539           0.681   \n",
       "LPD            0.653        0.463           0.628           0.704   \n",
       "LRDA           0.738        0.668           0.638           0.762   \n",
       "Other          0.453        0.390           0.392           0.529   \n",
       "Seizure        0.602        0.387           0.566           0.604   \n",
       "\n",
       "         Coef Energy  Teager Kaiser  \n",
       "GPD            0.834          0.821  \n",
       "GRDA           0.657          0.681  \n",
       "LPD            0.714          0.709  \n",
       "LRDA           0.733          0.789  \n",
       "Other          0.460          0.521  \n",
       "Seizure        0.561          0.602  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores.round(decimals = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ddd1e2",
   "metadata": {},
   "source": [
    "### ECG Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7c301314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scale_ecg(data, row):\n",
    "    ecg = np.asarray(get_sub_eeg(data, row)['EKG'])\n",
    "    ecg = pd.DataFrame(ecg, columns = ['EKG'])\n",
    "    scaler = MinMaxScaler()\n",
    "    ecg = scaler.fit_transform(ecg)\n",
    "    return ecg.ravel()\n",
    "\n",
    "def get_ecg_stats(ecg):\n",
    "    ecg_stats = np.asarray([np.mean(ecg), np.var(ecg), kurtosis(ecg), skew(ecg)])\n",
    "    return pd.DataFrame(ecg_stats, index = ['Mean', 'Variance', 'Kurtosis', 'Skewness']).transpose()\n",
    "\n",
    "def ecg_stats_df(data, size):\n",
    "    rows = [i for i in range(data.shape[0])]\n",
    "    random_rows = np.random.choice(rows, size = size, replace = False)\n",
    "    ecg_stats_set = pd.DataFrame()\n",
    "    for i in random_rows:\n",
    "        ecg = load_scale_ecg(data, i)\n",
    "        ecg_stats = get_ecg_stats(ecg)\n",
    "        ecg_stats_set = pd.concat([ecg_stats_set, ecg_stats], ignore_index = True)\n",
    "    return ecg_stats_set\n",
    "\n",
    "def full_ecg_stats_df(size, activity_df_list):\n",
    "    ecg_stats_feature_set = pd.DataFrame()\n",
    "    for df in activity_df_list:\n",
    "        ecg_stats_set = ecg_stats_df(df, size)\n",
    "        ecg_stats_feature_set = pd.concat([ecg_stats_feature_set, ecg_stats_set], ignore_index = True)\n",
    "    return ecg_stats_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "62629fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ecg_stats_df = full_ecg_stats_df(2000, activity_df_list)\n",
    "#ecg_stats_df.to_csv('ecg_stats_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4dd903d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('ecg_stats_df.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55dfc58",
   "metadata": {},
   "source": [
    "### Worst Results  \n",
    "  \n",
    "Extracting statistical features from the ECG data was not effective. 44% testing accuracy is by far the worst result of any feature set. Maybe over smaller intervals there would be more useful information here, but it's likely that in order to get useful information from the ECG data, the approach would be to determine HVR. If there were more than a week and a half left this semester, I'd work on figuring out how to go about doing that, but for this project, I'll be moving forward without ECG features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b9215296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG Statistical Features Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.53      0.74      0.62      1794\n",
      "        GRDA       0.56      0.66      0.61      1819\n",
      "         LPD       0.61      0.59      0.60      1800\n",
      "        LRDA       0.65      0.65      0.65      1795\n",
      "       Other       0.57      0.39      0.46      1808\n",
      "     Seizure       0.64      0.51      0.57      1784\n",
      "\n",
      "    accuracy                           0.59     10800\n",
      "   macro avg       0.59      0.59      0.58     10800\n",
      "weighted avg       0.59      0.59      0.58     10800\n",
      "\n",
      "ECG Statistical Features Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.47      0.61      0.53       206\n",
      "        GRDA       0.36      0.44      0.40       181\n",
      "         LPD       0.40      0.41      0.41       200\n",
      "        LRDA       0.52      0.56      0.54       205\n",
      "       Other       0.30      0.19      0.23       192\n",
      "     Seizure       0.52      0.40      0.45       216\n",
      "\n",
      "    accuracy                           0.44      1200\n",
      "   macro avg       0.43      0.44      0.43      1200\n",
      "weighted avg       0.43      0.44      0.43      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('ECG Statistical Features Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('ECG Statistical Features Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "ecg_stats_acc = accuracy_score(y_test, testing_yhat)\n",
    "ecg_stats_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "ecg_stats_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "44feef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['ECG Stats'] = ecg_stats_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc47942",
   "metadata": {},
   "source": [
    "### Hjorth Time Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "31b3b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv('time_comp_df.csv')\n",
    "X2 = pd.read_csv('time_mob_df.csv')\n",
    "cols1, cols2 = X1.columns, X2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb67515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X1 = scaler.fit_transform(X1)\n",
    "X1 = pd.DataFrame(X1, columns = cols1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X2 = scaler.fit_transform(X2)\n",
    "X2 = pd.DataFrame(X2, columns = cols2)\n",
    "\n",
    "X = pd.concat([X1, X2], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1e479a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hjorth Time Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.78      0.92      0.85      1794\n",
      "        GRDA       0.83      0.83      0.83      1819\n",
      "         LPD       0.76      0.88      0.81      1800\n",
      "        LRDA       0.84      0.87      0.85      1795\n",
      "       Other       0.78      0.58      0.67      1808\n",
      "     Seizure       0.79      0.70      0.74      1784\n",
      "\n",
      "    accuracy                           0.80     10800\n",
      "   macro avg       0.80      0.80      0.79     10800\n",
      "weighted avg       0.80      0.80      0.79     10800\n",
      "\n",
      "Hjorth Time Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.73      0.83      0.78       206\n",
      "        GRDA       0.65      0.71      0.68       181\n",
      "         LPD       0.64      0.72      0.68       200\n",
      "        LRDA       0.75      0.80      0.77       205\n",
      "       Other       0.49      0.38      0.42       192\n",
      "     Seizure       0.68      0.55      0.61       216\n",
      "\n",
      "    accuracy                           0.67      1200\n",
      "   macro avg       0.66      0.67      0.66      1200\n",
      "weighted avg       0.66      0.67      0.66      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Hjorth Time Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Hjorth Time Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "hjorth_time_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "hjorth_time_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "hjorth_time_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "hjorth_time_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "912d0bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.795, 0.667)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hjorth_time_train, hjorth_time_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742c855",
   "metadata": {},
   "source": [
    "### Hjorth Frequency Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74f8539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv('freq_comp_df.csv')\n",
    "X2 = pd.read_csv('spectral_mob_df.csv')\n",
    "cols1, cols2 = X1.columns, X2.columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X1 = scaler.fit_transform(X1)\n",
    "X1 = pd.DataFrame(X1, columns = cols1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X2 = scaler.fit_transform(X2)\n",
    "X2 = pd.DataFrame(X2, columns = cols2)\n",
    "\n",
    "X = pd.concat([X1, X2], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ef67427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hjorth Frequency Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.74      0.89      0.81      1794\n",
      "        GRDA       0.71      0.79      0.75      1819\n",
      "         LPD       0.69      0.81      0.74      1800\n",
      "        LRDA       0.77      0.83      0.80      1795\n",
      "       Other       0.73      0.50      0.60      1808\n",
      "     Seizure       0.79      0.58      0.67      1784\n",
      "\n",
      "    accuracy                           0.73     10800\n",
      "   macro avg       0.74      0.73      0.73     10800\n",
      "weighted avg       0.74      0.73      0.73     10800\n",
      "\n",
      "Hjorth Frequency Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.66      0.77      0.71       206\n",
      "        GRDA       0.56      0.66      0.61       181\n",
      "         LPD       0.54      0.63      0.58       200\n",
      "        LRDA       0.66      0.75      0.70       205\n",
      "       Other       0.46      0.31      0.37       192\n",
      "     Seizure       0.64      0.45      0.53       216\n",
      "\n",
      "    accuracy                           0.59      1200\n",
      "   macro avg       0.59      0.59      0.58      1200\n",
      "weighted avg       0.59      0.59      0.58      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Hjorth Frequency Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Hjorth Frequency Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "hjorth_freq_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "hjorth_freq_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "hjorth_freq_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "hjorth_freq_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a6cb6bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.734, 0.595)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hjorth_freq_train, hjorth_freq_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcca979",
   "metadata": {},
   "source": [
    "### Hjorth Altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be627641",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv('time_comp_df.csv')\n",
    "X2 = pd.read_csv('time_mob_df.csv')\n",
    "X3 = pd.read_csv('freq_comp_df.csv')\n",
    "X4 = pd.read_csv('spectral_mob_df.csv')\n",
    "cols1, cols2 = X1.columns, X2.columns\n",
    "cols3, cols4 = X3.columns, X4.columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X1 = scaler.fit_transform(X1)\n",
    "X1 = pd.DataFrame(X1, columns = cols1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X2 = scaler.fit_transform(X2)\n",
    "X2 = pd.DataFrame(X2, columns = cols2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X3 = scaler.fit_transform(X3)\n",
    "X3 = pd.DataFrame(X3, columns = cols3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X4 = scaler.fit_transform(X4)\n",
    "X4 = pd.DataFrame(X4, columns = cols4)\n",
    "\n",
    "X = pd.concat([X1, X2], axis = 1)\n",
    "X = pd.concat([X, X3], axis = 1)\n",
    "X = pd.concat([X, X4], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe8e1b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hjorth Altogether Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.77      0.92      0.84      1794\n",
      "        GRDA       0.82      0.83      0.83      1819\n",
      "         LPD       0.77      0.87      0.82      1800\n",
      "        LRDA       0.83      0.87      0.85      1795\n",
      "       Other       0.80      0.59      0.68      1808\n",
      "     Seizure       0.80      0.72      0.75      1784\n",
      "\n",
      "    accuracy                           0.80     10800\n",
      "   macro avg       0.80      0.80      0.79     10800\n",
      "weighted avg       0.80      0.80      0.79     10800\n",
      "\n",
      "Hjorth Altogether Testing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPD       0.71      0.85      0.77       206\n",
      "        GRDA       0.63      0.72      0.67       181\n",
      "         LPD       0.64      0.71      0.67       200\n",
      "        LRDA       0.74      0.77      0.76       205\n",
      "       Other       0.57      0.38      0.46       192\n",
      "     Seizure       0.70      0.59      0.64       216\n",
      "\n",
      "    accuracy                           0.67      1200\n",
      "   macro avg       0.67      0.67      0.66      1200\n",
      "weighted avg       0.67      0.67      0.66      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "training_yhat = knn.predict(X_train)\n",
    "testing_yhat = knn.predict(X_test)\n",
    "print('Hjorth Altogether Training')\n",
    "print(classification_report(y_train, training_yhat))\n",
    "print('Hjorth Altogether Testing')\n",
    "print(classification_report(y_test, testing_yhat))\n",
    "hjorth_train = accuracy_score(y_train, training_yhat).round(decimals = 3)\n",
    "hjorth_test = accuracy_score(y_test, testing_yhat).round(decimals = 3)\n",
    "hjorth_macro_f1 = f1_score(y_test, testing_yhat, average = 'macro')\n",
    "hjorth_f1 = f1_score(y_test, testing_yhat, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0038bac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.797, 0.672)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hjorth_train, hjorth_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca1c14",
   "metadata": {},
   "source": [
    "### Visualization of Results  \n",
    "  \n",
    "Below I'm going to make some bar plots to compare the different feature sets tested above. I've realized that because of the way I wrote my functions, everytime I make a feature set, a new random set of indexes is chosen. These feature sets aren't extracted from the same sub EEGs and that means I can't concatenate them and test them together. I'll have to re-do that in a separate notebook. Once I've done that testing, I'll begin working on dimensionality reduction, feature selection, and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "77919201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [bandpow_train, higuchi_train, zero_xing_train, tk_energy_train, hjorth_train]\n",
    "test_scores = [bandpow_test, higuchi_test, zero_xing_test, tk_energy_test, hjorth_test]\n",
    "feature_types = ['Band Power', 'Higuchi FD', 'Zero Crossings', 'TK Energy', 'Mobility & Complexity']\n",
    "feature_sets = ['Set {}'.format(i) for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "00c76f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_axis = np.arange(len(feature_sets))\n",
    "\n",
    "plt.bar(X_axis - 0.2, train_scores, 0.4, label = 'Training', color = 'skyblue') \n",
    "plt.bar(X_axis + 0.2, test_scores, 0.4, label = 'Testing', color = 'lightgreen') \n",
    "  \n",
    "plt.xticks(X_axis, feature_sets)\n",
    "plt.ylabel('Accuracy') \n",
    "plt.title('Comparing Feature Types')\n",
    "plt.legend(bbox_to_anchor = [1, 1], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ac15f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table = pd.DataFrame([feature_types, train_scores, test_scores],\n",
    "                             index = ['Feature Type', 'Training', 'Testing'],\n",
    "                             columns = feature_sets).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a2fd779c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Type</th>\n",
       "      <th>Training</th>\n",
       "      <th>Testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Set 1</th>\n",
       "      <td>Band Power</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set 2</th>\n",
       "      <td>Higuchi FD</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set 3</th>\n",
       "      <td>Zero Crossings</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set 4</th>\n",
       "      <td>TK Energy</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set 5</th>\n",
       "      <td>Mobility &amp; Complexity</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature Type Training Testing\n",
       "Set 1             Band Power    0.818   0.703\n",
       "Set 2             Higuchi FD    0.798   0.677\n",
       "Set 3         Zero Crossings    0.801   0.663\n",
       "Set 4              TK Energy    0.801   0.678\n",
       "Set 5  Mobility & Complexity    0.797   0.672"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eeca3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
